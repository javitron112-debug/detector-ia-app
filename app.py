import streamlit as st
import numpy as np
import pickle
import nltk
from nltk.tokenize import word_tokenize, sent_tokenize
import warnings
warnings.filterwarnings('ignore')

# Configuraci√≥n de la p√°gina
st.set_page_config(
    page_title="Detector de IA en Textos",
    page_icon="ü§ñ",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Descargar recursos de NLTK al inicio
@st.cache_resource
def download_nltk_resources():
    nltk.download('punkt', quiet=True)
    nltk.download('punkt_tab', quiet=True)

download_nltk_resources()

# T√≠tulo principal con estilo
st.markdown("""
<style>
    .main-header {
        font-size: 2.5rem;
        color: #1E88E5;
        text-align: center;
        margin-bottom: 1rem;
    }
    .sub-header {
        font-size: 1.2rem;
        color: #666;
        text-align: center;
        margin-bottom: 2rem;
    }
    .result-box {
        padding: 1.5rem;
        border-radius: 10px;
        margin: 1rem 0;
        border-left: 5px solid;
    }
    .human-box {
        background-color: #E8F5E9;
        border-left-color: #4CAF50;
    }
    .ai-box {
        background-color: #FFEBEE;
        border-left-color: #F44336;
    }
    .metric-card {
        background-color: #f8f9fa;
        padding: 1rem;
        border-radius: 10px;
        border: 1px solid #dee2e6;
    }
</style>
""", unsafe_allow_html=True)

# T√≠tulo
st.markdown('<h1 class="main-header">üîç Detector de IA en Textos</h1>', unsafe_allow_html=True)
st.markdown('<p class="sub-header">Analiza si un texto fue escrito por un humano o generado por inteligencia artificial</p>', unsafe_allow_html=True)

class SimpleDetector:
    """Detector simple basado en heur√≠sticas"""
    
    def __init__(self):
        self.features = {}
    
    def extract_features(self, text):
        """Extrae caracter√≠sticas del texto"""
        features = {}
        
        # Caracter√≠sticas b√°sicas
        features['length'] = len(text)
        features['word_count'] = len(text.split())
        features['sentence_count'] = len(sent_tokenize(text))
        
        # Caracter√≠sticas de complejidad
        words = word_tokenize(text.lower())
        unique_words = set(words)
        
        features['unique_word_ratio'] = len(unique_words) / max(len(words), 1)
        features['avg_word_length'] = np.mean([len(w) for w in words]) if words else 0
        
        # Caracter√≠sticas sint√°cticas
        sentences = sent_tokenize(text)
        sentence_lengths = [len(sent.split()) for sent in sentences]
        
        features['avg_sentence_length'] = np.mean(sentence_lengths) if sentence_lengths else 0
        features['sentence_length_variance'] = np.var(sentence_lengths) if len(sentence_lengths) > 1 else 0
        
        # Caracter√≠sticas de puntuaci√≥n
        features['comma_density'] = text.count(',') / max(len(text.split()), 1)
        features['exclamation_density'] = text.count('!') / max(len(text.split()), 1)
        
        # Detecci√≥n de patrones comunes de IA
        ai_patterns = [
            'es importante destacar',
            'en conclusi√≥n',
            'por otro lado',
            'sin embargo',
            'adem√°s',
            'por lo tanto',
            'en primer lugar',
            'en segundo lugar',
            'cabe mencionar',
            'es fundamental'
        ]
        
        features['ai_pattern_count'] = sum(1 for pattern in ai_patterns if pattern in text.lower())
        
        # Burstiness (variabilidad en longitud de oraciones)
        if len(sentence_lengths) > 1 and np.mean(sentence_lengths) > 0:
            features['burstiness'] = np.std(sentence_lengths) / np.mean(sentence_lengths)
        else:
            features['burstiness'] = 0
        
        self.features = features
        return features
    
    def predict(self, text):
        """Predice si el texto es de IA"""
        features = self.extract_features(text)
        
        # Puntuaci√≥n basada en heur√≠sticas
        score = 0
        
        # 1. Uniformidad en longitud de oraciones (IA tiende a ser m√°s uniforme)
        if features['sentence_length_variance'] < 20:
            score += 0.2
        
        # 2. Densidad de comas (IA usa m√°s puntuaci√≥n estructurada)
        if features['comma_density'] > 0.08:
            score += 0.15
        
        # 3. Patrones de lenguaje de IA
        score += min(features['ai_pattern_count'] * 0.05, 0.3)
        
        # 4. Baja burstiness (IA tiene menos variaci√≥n)
        if features['burstiness'] < 0.5:
            score += 0.1
        
        # 5. Baja densidad de exclamaciones (IA es m√°s formal)
        if features['exclamation_density'] < 0.01:
            score += 0.05
        
        # 6. Longitud promedio de palabras (IA puede usar palabras m√°s largas)
        if features['avg_word_length'] > 5:
            score += 0.05
        
        # Ajustar por longitud del texto
        if features['word_count'] < 50:
            score *= 0.7  # Menos confiable en textos cortos
        
        # Limitar score entre 0 y 1
        score = min(max(score, 0), 0.95)
        
        # Determinar confianza
        confidence = "Alta" if abs(score - 0.5) > 0.3 else "Media" if abs(score - 0.5) > 0.15 else "Baja"
        
        return {
            'prediction': 'IA ü§ñ' if score > 0.5 else 'Humano üë§',
            'probability': float(score),
            'confidence': confidence,
            'features': features
        }

# Inicializar detector
@st.cache_resource
def get_detector():
    return SimpleDetector()

detector = get_detector()

# Sidebar
with st.sidebar:
    st.markdown("### ‚öôÔ∏è Configuraci√≥n")
    
    # Modo de an√°lisis
    analysis_mode = st.selectbox(
        "Modo de an√°lisis",
        ["R√°pido", "Detallado", "Comparativo"]
    )
    
    # Umbral de detecci√≥n
    threshold = st.slider(
        "Umbral de sensibilidad",
        min_value=0.3,
        max_value=0.7,
        value=0.5,
        step=0.05,
        help="Ajusta qu√© tan estricto es el detector"
    )
    
    st.markdown("---")
    st.markdown("### üìä Estad√≠sticas")
    
    # Ejemplos predefinidos
    st.markdown("#### Ejemplos para probar:")
    
    example_texts = {
        "Texto Humano (Conversacional)": "Hoy fui al mercado y compr√© unas manzanas. Estaban un poco caras, pero me gusta su sabor. De camino a casa me encontr√© con mi vecina Mar√≠a, que me cont√≥ que se va de vacaciones la semana que viene.",
        "Texto IA (Formal)": "La inteligencia artificial constituye un paradigma tecnol√≥gico transformacional que est√° redefiniendo los procesos empresariales contempor√°neos. Es fundamental considerar los aspectos √©ticos inherentes a su implementaci√≥n para garantizar un desarrollo sostenible y equitativo.",
        "Texto Mixto": "Los modelos de lenguaje como GPT son incre√≠blemente √∫tiles. Personalmente, los uso para ayudarme con tareas de escritura, aunque a veces cometen errores graciosos. Es importante verificar siempre la informaci√≥n que proporcionan.",
    }
    
    selected_example = st.selectbox("Cargar ejemplo:", list(example_texts.keys()))
    
    if st.button("Cargar ejemplo seleccionado"):
        st.session_state.text_input = example_texts[selected_example]
    
    st.markdown("---")
    st.markdown("### ‚ÑπÔ∏è Acerca de")
    st.markdown("""
    Esta herramienta analiza patrones en el texto para determinar si fue generado por IA.
    
    **Precisi√≥n estimada:** ~70-80%
    
    **Limitaciones:**
    - Textos cortos son m√°s dif√≠ciles
    - No es 100% preciso
    - Los textos editados pueden confundir
    
    **Desarrollado con:** Python, Streamlit, NLTK
    """)

# √Årea principal de la aplicaci√≥n
col1, col2 = st.columns([2, 1])

with col1:
    st.markdown("### üìù Ingresa el texto a analizar")
    
    # Text area con valor de sesi√≥n
    text_input = st.text_area(
        "Pega tu texto aqu√≠:",
        height=250,
        value=st.session_state.get('text_input', ''),
        placeholder="Escribe o pega el texto que quieres analizar aqu√≠..."
    )
    
    # Botones de acci√≥n
    col1_1, col1_2, col1_3 = st.columns(3)
    
    with col1_1:
        analyze_btn = st.button("üîç Analizar Texto", type="primary", use_container_width=True)
    
    with col1_2:
        clear_btn = st.button("üßπ Limpiar", use_container_width=True)
    
    with col1_3:
        sample_btn = st.button("üé≤ Texto Aleatorio", use_container_width=True)
    
    if clear_btn:
        st.session_state.text_input = ""
        st.rerun()
    
    if sample_btn:
        samples = [
            "El aprendizaje autom√°tico ha revolucionado la forma en que procesamos datos. Sin embargo, es crucial mantener un enfoque humanoc√©ntrico en su desarrollo.",
            "Ayer por la tarde, mientras paseaba por el parque, vi a un par de ni√±os jugando al f√∫tbol. Uno de ellos meti√≥ un gol incre√≠ble desde lejos, todos nos quedamos boquiabiertos.",
            "La sostenibilidad ambiental representa uno de los desaf√≠os m√°s apremiantes de nuestra era. En consecuencia, la adopci√≥n de energ√≠as renovables se ha convertido en una prioridad estrat√©gica a nivel global."
        ]
        import random
        st.session_state.text_input = random.choice(samples)
        st.rerun()

with col2:
    st.markdown("### üìà M√©tricas de Texto")
    
    if text_input:
        # Calcular m√©tricas b√°sicas
        words = len(text_input.split())
        sentences = len(sent_tokenize(text_input))
        chars = len(text_input.replace(" ", ""))
        
        st.metric("Palabras", words)
        st.metric("Oraciones", sentences)
        st.metric("Caracteres", chars)
        
        if words > 0:
            st.metric("Palabras/Oraci√≥n", f"{words/max(sentences,1):.1f}")
    else:
        st.info("Ingresa un texto para ver las m√©tricas")

# An√°lisis principal
if analyze_btn and text_input.strip():
    with st.spinner("Analizando texto..."):
        # Realizar predicci√≥n
        result = detector.predict(text_input)
        
        # Mostrar resultado principal
        st.markdown("---")
        st.markdown("## üìä Resultado del An√°lisis")
        
        # Tarjeta de resultado
        if result['prediction'] == 'IA ü§ñ':
            box_class = "ai-box"
            emoji = "ü§ñ"
            color = "#F44336"
        else:
            box_class = "human-box"
            emoji = "üë§"
            color = "#4CAF50"
        
        st.markdown(f"""
        <div class="result-box {box_class}">
            <h2 style="margin-top: 0;">{emoji} {result['prediction']}</h2>
            <p><strong>Probabilidad de ser IA:</strong> {result['probability']:.1%}</p>
            <p><strong>Nivel de confianza:</strong> {result['confidence']}</p>
        </div>
        """, unsafe_allow_html=True)
        
        # Barra de progreso
        prob_percent = result['probability'] * 100
        st.progress(float(result['probability']), 
                   text=f"Score IA: {prob_percent:.1f}%")
        
        # An√°lisis detallado
        if analysis_mode in ["Detallado", "Comparativo"]:
            st.markdown("### üîç An√°lisis Detallado")
            
            features = result['features']
            
            cols = st.columns(4)
            metrics = [
                ("Riqueza L√©xica", f"{features['unique_word_ratio']:.1%}"),
                ("Long. Prom. Palabra", f"{features['avg_word_length']:.1f}"),
                ("Palabras/Oraci√≥n", f"{features['avg_sentence_length']:.1f}"),
                ("Burstiness", f"{features['burstiness']:.3f}")
            ]
            
            for col, (label, value) in zip(cols, metrics):
                with col:
                    st.metric(label, value)
            
            # Interpretaci√≥n de caracter√≠sticas
            st.markdown("#### üìù Interpretaci√≥n:")
            
            interpretations = []
            
            if features['ai_pattern_count'] > 2:
                interpretations.append("**Patrones de IA detectados**: El texto contiene frases com√∫nmente usadas por modelos de lenguaje")
            
            if features['burstiness'] < 0.5:
                interpretations.append("**Baja variabilidad**: Las oraciones tienen longitudes similares (com√∫n en textos de IA)")
            
            if features['comma_density'] > 0.1:
                interpretations.append("**Alta densidad de comas**: Estructura sint√°ctica compleja y formal")
            
            if features['unique_word_ratio'] < 0.4 and features['word_count'] > 50:
                interpretations.append("**Vocabulario limitado**: Repetici√≥n de palabras comunes")
            
            for interp in interpretations:
                st.markdown(f"- {interp}")
        
        # Comparativo
        if analysis_mode == "Comparativo":
            st.markdown("### üìä An√°lisis Comparativo")
            
            # Crear datos comparativos
            import plotly.graph_objects as go
            
            fig = go.Figure()
            
            features_plot = ['unique_word_ratio', 'burstiness', 'comma_density', 'ai_pattern_count']
            labels = ['Riqueza L√©xica', 'Burstiness', 'Densidad Comas', 'Patrones IA']
            values = [features[f] for f in features_plot]
            
            # Normalizar valores para el radar chart
            normalized_values = []
            max_vals = [1.0, 2.0, 0.2, 5.0]  # Valores m√°ximos esperados
            
            for val, max_val in zip(values, max_vals):
                normalized_values.append(min(val / max_val, 1.0))
            
            fig.add_trace(go.Scatterpolar(
                r=normalized_values + [normalized_values[0]],
                theta=labels + [labels[0]],
                fill='toself',
                name='Tu texto',
                line_color=color
            ))
            
            fig.update_layout(
                polar=dict(
                    radialaxis=dict(
                        visible=True,
                        range=[0, 1]
                    )),
                showlegend=True,
                title="Perfil de Caracter√≠sticas del Texto"
            )
            
            st.plotly_chart(fig, use_container_width=True)
        
        # Consejos
        st.markdown("### üí° Consejos")
        
        if result['prediction'] == 'IA ü§ñ' and result['probability'] > 0.7:
            st.warning("""
            **Posible texto generado por IA detectado:**
            - Considera revisar el contenido cr√≠ticamente
            - Verifica fuentes adicionales si es informaci√≥n importante
            - Los textos de IA pueden contener errores f√°cticos o sesgos
            """)
        elif result['prediction'] == 'Humano üë§' and result['probability'] < 0.3:
            st.success("""
            **Caracter√≠sticas de texto humano identificadas:**
            - Variabilidad natural en estilo
            - Patrones conversacionales
            - Posibles imperfecciones gramaticales menores
            """)
        else:
            st.info("""
            **Resultado indeterminado:**
            - El texto muestra caracter√≠sticas tanto humanas como de IA
            - Podr√≠a ser texto humano muy bien escrito
            - O texto de IA editado o modificado
            """)
        
        # Advertencia
        st.markdown("---")
        st.markdown("""
        <div style="background-color: #FFF3CD; padding: 1rem; border-radius: 5px; border-left: 4px solid #FFC107;">
        <strong>‚ö†Ô∏è Limitaci√≥n importante:</strong> Esta herramienta es una ayuda para el an√°lisis, 
        pero no debe usarse como √∫nico criterio para determinar la autor√≠a de un texto. 
        La precisi√≥n no es del 100% y pueden ocurrir falsos positivos/negativos.
        </div>
        """, unsafe_allow_html=True)

elif analyze_btn and not text_input.strip():
    st.warning("‚ö†Ô∏è Por favor, ingresa un texto para analizar")

# Footer
st.markdown("---")
col_f1, col_f2, col_f3 = st.columns(3)

with col_f2:
    st.markdown("""
    <div style="text-align: center; color: #666; font-size: 0.9rem;">
    <p>üîç Detector de IA v1.0 | üìö Uso educativo | ‚öñÔ∏è Herramienta de an√°lisis</p>
    <p>Desplegado en <a href="https://share.streamlit.io" target="_blank">Streamlit Sharing</a></p>
    </div>
    """, unsafe_allow_html=True)
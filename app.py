import streamlit as st
import re
from pypdf import PdfReader
from docx import Document
import nltk

# --- CONFIGURACI√ìN DE LA P√ÅGINA ---
st.set_page_config(page_title="Humanizador de Texto", layout="wide")

# --- CORRECCI√ìN DEL ERROR DE NLTK ---
# Descargamos expl√≠citamente ambos recursos necesarios para evitar el error "punkt_tab not found"
try:
    nltk.data.find('tokenizers/punkt')
except LookupError:
    nltk.download('punkt')

try:
    nltk.data.find('tokenizers/punkt_tab')
except LookupError:
    nltk.download('punkt_tab')

# --- LISTA DE FRASES COMUNES DE IA (EN ESPA√ëOL) ---
AI_PHRASES = [
    "En primer lugar", "En segundo t√©rmino", "Por una parte... por otra", 
    "A continuaci√≥n", "Asimismo", "De igual manera", "Del mismo modo",
    "En consecuencia", "Por lo tanto", "As√≠ pues", "De ah√≠ que",
    "En otras palabras", "Es decir", "Esto significa que",
    "A modo de ejemplo", "Para ilustrar esto", "Pongamos por caso",
    "Resulta fundamental", "Es de vital importancia", "Conviene subrayar",
    "Vale la pena recordar", "Cabe resaltar que", "Es relevante apuntar",
    "Como punto de partida", "En t√©rminos generales", "Desde una perspectiva amplia",
    "Hist√≥ricamente", "Tradicionalmente", "En la actualidad",
    "En comparaci√≥n con", "A diferencia de", "Por el contrario",
    "Si bien es cierto que", "A pesar de que", "Aun cuando",
    "Esto plantea la cuesti√≥n de", "Surge entonces la pregunta",
    "Desde un punto de vista cr√≠tico", "Analizando en profundidad",
    "En definitiva", "A modo de s√≠ntesis", "En esencia",
    "Para finalizar", "Como colof√≥n", "En l√≠neas generales",
    "El principal hallazgo es", "La conclusi√≥n principal radica en",
    "En √∫ltima instancia", "A fin de cuentas",
    "Eficiente", "√ìptimo", "Preciso", "Robusto", "Escalable",
    "Paradigma", "Marco conceptual", "Ecosistema",
    "Leveraje", "Sinergia", "Potenciar",
    "Interconectado", "Interdependiente", "Hol√≠stico",
    "Estado del arte", "Algoritmo", "Modelo predictivo", "Conjunto de datos",
    "Capacidad de generalizaci√≥n", "Procesamiento del lenguaje natural (PLN)",
    "Por lo general", "En la mayor√≠a de los casos", "Suele ocurrir que",
    "Es probable que", "Podr√≠a considerarse", "Existe la posibilidad de",
    "Seg√∫n los datos disponibles", "Bas√°ndonos en la informaci√≥n proporcionada",
    "Es recomendable", "Se sugiere", "Podr√≠a ser beneficioso",
    "Para responder a tu pregunta", "Me preguntas sobre", "Entiendo que buscas",
    "Voy a desglosarlo", "Perm√≠teme explicarlo paso a paso",
    "¬øTe gustar√≠a que profundice en alg√∫n punto en particular?",
    "Es un tema complejo, pero intentar√© simplificarlo"
]

# --- FUNCIONES DE EXTRACCI√ìN ---

def read_txt(file):
    return str(file.read(), "utf-8")

def read_pdf(file):
    pdf = PdfReader(file)
    text = ""
    for page in pdf.pages:
        text += page.extract_text() or ""
    return text

def read_docx(file):
    doc = Document(file)
    text = []
    for para in doc.paragraphs:
        text.append(para.text)
    return "\n".join(text)

# --- MOTOR DE AN√ÅLISIS ---

def analyze_and_highlight(text):
    """
    Analiza el texto buscando patrones de IA y devuelve HTML resaltado.
    """
    highlighted_text = text
    
    # 1. Resaltar frases comunes de IA (Color Amarillo)
    # Usamos Regex para reemplazar sin importar may√∫sculas/min√∫sculas
    for phrase in AI_PHRASES:
        pattern = re.compile(re.escape(phrase), re.IGNORECASE)
        # El <span> a√±ade el fondo amarillo
        highlighted_text = pattern.sub(
            f'<span style="background-color: #ffd700; color: black; font-weight: bold; padding: 2px; border-radius: 3px;" title="Frase com√∫n de IA">{phrase}</span>', 
            highlighted_text
        )
    
    # Contamos cu√°ntas frases de IA se encontraron para las m√©tricas
    count_ai_phrases = sum(1 for phrase in AI_PHRASES if phrase in text.lower())
    
    # Usamos sent_tokenize solo para verificar que NLTK funciona, 
    # aunque en este MVP no estamos modificando la estructura de oraciones visualmente.
    try:
        sentences = nltk.tokenize.sent_tokenize(text)
        num_sentences = len(sentences)
    except Exception as e:
        num_sentences = 0
        print(f"Error en tokenizaci√≥n: {e}")
    
    return highlighted_text, count_ai_phrases, num_sentences

# --- INTERFAZ DE USUARIO (STREAMLIT) ---

st.title("üïµÔ∏è Detector y Humanizador de Textos")
st.markdown("""
### ¬øC√≥mo funciona?
Sube tu documento y la herramienta resaltar√° patrones repetitivos.
* <span style="background-color: #ffd700; color: black; padding: 2px; border-radius: 3px;">**Amarillo**</span>: Conectores y "muletillas" que delatan a ChatGPT/Claude.
""", unsafe_allow_html=True)

uploaded_file = st.sidebar.file_uploader("Sube tu archivo", type=["txt", "pdf", "docx"])

if uploaded_file is not None:
    file_type = uploaded_file.name.split(".")[-1]
    raw_text = ""

    # Procesar archivo seg√∫n tipo
    try:
        if file_type == "txt":
            raw_text = read_txt(uploaded_file)
        elif file_type == "pdf":
            raw_text = read_pdf(uploaded_file)
        elif file_type == "docx":
            raw_text = read_docx(uploaded_file)
        
        st.success(f"Archivo **{uploaded_file.name}** cargado.")
        
        # Bot√≥n de an√°lisis
        if st.button("üîç Analizar Texto"):
            if not raw_text.strip():
                st.warning("El documento parece estar vac√≠o o no se pudo leer el texto.")
            else:
                with st.spinner("Escaneando patrones..."):
                    html_result, count, num_sentences = analyze_and_highlight(raw_text)
                
                # M√©tricas
                col1, col2, col3 = st.columns(3)
                col1.metric("Palabras Totales", len(raw_text.split()))
                col2.metric("Oraciones", num_sentences)
                col3.metric("Frases 'Rob√≥ticas'", count, delta_color="inverse")
                
                st.markdown("---")
                st.subheader("üìù Resultado del An√°lisis")
                st.info("Sugerencia: Reescribe las partes amarillas usando un lenguaje m√°s coloquial o directo.")
                
                # Caja con el texto resaltado (Scrollable)
                st.markdown(
                    f"""
                    <div style="
                        padding: 20px; 
                        border: 1px solid #ccc; 
                        border-radius: 10px; 
                        background-color: white; 
                        color: #333; 
                        line-height: 1.8; 
                        height: 500px; 
                        overflow-y: scroll;
                        font-family: Arial, sans-serif;
                    ">
                        {html_result}
                    </div>
                    """, 
                    unsafe_allow_html=True
                )

    except Exception as e:
        st.error(f"Ocurri√≥ un error al procesar el archivo: {e}")

else:
    st.info("üëà Sube un archivo TXT, PDF o DOCX desde el men√∫ lateral.")